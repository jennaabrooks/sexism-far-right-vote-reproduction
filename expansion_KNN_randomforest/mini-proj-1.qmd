---
title: "Mini-Project 1: Demographic and Ideological Influence on Voter Intent in Spanish Elections"
author: Group 4 - Sara Hamidi, Shirley Augustin, Jenna Brooks, Allison Park
format: pdf
editor: visual
---

# Introduction and Hypothesis

Spain’s political system is highly pluralistic and decentralized, with over 20 active political parties. The major political parties reflect various stances on issues such as immigration and sexism which differentiate them across the political spectrum, with far right parties typically promoting anti-feminist and anti-immigrant rhetoric in much of their political discourse (Anduiza and Rico 2024) while other far left parties claim the opposite. We aim to answer the question: Can the beliefs of Spanish citizens regarding sexism and immigration be used to predict their voting intentions in the Spanish elections?

In this project, we use Spanish Political Attitudes data to test methods for classifying respondents’ intentions to vote for 6 of the major Spanish political parties spanning from the far left to far right political spectrum (see Appendix A for details on Spain’s political spectrum). We hypothesize that methods such as k-nearest neighbors or random forest classifiers will be able to predict which party a respondent intends to vote for, using the survey response variables regarding political beliefs (nativism, sexism, and participation in Women’s Day protests) and demographic features (income and sex). 

We expect parties on the far ends of the political spectrum to be easier to classify than center parties due to the mobilization of issues like sexism and immigration by more ideologically extreme parties to distinguish themselves and galvanize their voter base. By exploring the link between social attitudes and voting intentions, this study sheds light on the extent to which ideological polarization around issues like immigration and sexism influences party alignment in Spain's increasingly fragmented political landscape.

# Methods

We use data from the Spanish Political Attitudes dataset (Hernández Pérez et al. 2021). The survey uses a quota sampling method to ensure a representative sample of the Spanish adult population aged 18 to 56, with quotas based on gender, age, educational background, geographic region, and municipality size.  It also includes respondents’ answers to questions on sexism, voting intention, participation in feminist protests, and beliefs surrounding immigration. The raw data comprises 7,850 observations and the unit of analysis is individual voters in Spain. When cleaned to the parties of interest and after removing NA’s, the data contains 3,034 observations. 

We focused on the following covariates: `dincome_all`, `female`, `nativism`, `msexism`, and `femdemonstrate` with `voteintentionspain` of the 6 parties of interest as the dependent variable which we aim to classify. Our motivation behind including these covariates in particular align with our hypothesis that there is a correlation between people’s ideological beliefs and their political party affiliations. Moreover, we also include income as a demographic variable to assess whether gender and economic status influence party affiliation.

Within the `voteintentionspain` variable, the six political parties that we chose are:  the following: 

(numbers 1-23 indicate how they are coded in the data) 

-   1 - PSOE ( Center Left )

-   2 - PP ( Center Right )

-   3 - Podemos ( Far Left )

-   4 - Ciduadanos ( Centrist )

-   7 - ERC ( Catalonia )

-   23 - Vox ( Far Right )

Next, we explored the data distribution and it became clear that upon evaluation of the data distribution, there is a significant class imbalance among the political parties, with the PSOE party having 30% of the observations, followed closely by Ciduadanos ( 22.5% ) and Podemos ( 19.6% ) with the other three trailing far behind. Therein lies a challenge in producing a successful classification model: having a class that reflects 30% of the observations but another class that represents only 5.6%. Inevitably, this would lead to higher prediction rates for the majority class versus significantly less predictions for the minority classes. 

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

library(randomForest)
library(tidyverse)
library(caret)
library(ggplot2)
library(dplyr)
library(reshape2) 
library(nnet)
library(pROC)
```

```{r, echo=FALSE}

df <- read.csv("df_clean.csv")

df <- df |> 
  mutate(
    voteintentionspain = factor(voteintentionspain),
    edu3 = factor(edu3),
    female = factor(female),
    femdemonstrate = factor(femdemonstrate)
  )


# Create a proportion table as a data frame
df %>%
  count(voteintentionspain) %>%
  mutate(percentage = n / sum(n) * 100) %>%
  ggplot(aes(x = reorder(voteintentionspain, -percentage), y = percentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = sprintf("%.1f%%", percentage)), 
            vjust = -0.5, size = 4) +
  labs(title = "Distribution of Vote Intentions",
       x = "Vote Intention",
       y = NULL) +
  scale_x_discrete(labels = c(
    "1" = "PSOE",
    "2" = "PP",
    "3" = "Podemos",
    "4" = "Ciduadanos",
    "7" = "ERC",
    "23" = "VOX"
  )) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_cartesian(ylim = c(0, 35))

```

Our main objective is to predict which party a person intends to vote for, based on their demographics  and other ideological standpoints. Our main computational methods involve experimenting  with various classifiers such as K-Nearest Neighbors, random forests, and multinomial regression. KNN was chosen because it is non-parametric and can easily capture nonlinear relationships, since political attitudes often cluster spatially in feature space as people with similar beliefs vote similarly. Random forests similarly handle non-linearity well and offer feature importance metrics, which are helpful for interpreting which beliefs/demographics most influence vote intention. Multinomial regression is used as a baseline approach, assuming a linear relationship between variables.

To gain preliminary insights into how well we may be able to classify a voter’s political party affiliation based on the covariates above, we chose to run a multinomial regression. After fitting this model, we then conducted both an in-sample evaluation using a train vs. test set partition and calculated a correlation matrix and prediction accuracy, which we found to be about 40%. However, the issue with just fitting a multinomial logistic regression was that the output is probabilistic, rather than classification based. For our motives, we want a model that is robust, to avoid overfitting and that is able to identify complex relationships between variables. Because of this, we chose to run a Random Forest with the same covariates.

We hoped that the robustness of a random forest and the decision tree algorithm would be more insightful in identifying which variables are most influential in making predictions — the key to our questions regarding the influence of ideology on political party affiliation.

Once we ran our random forest, we then looked at its prediction accuracy in a confusion matrix, and to go even further, we plotted a variable importance plot to identify which features are most important in classifying voter’s intent. Through these insights, it became clear that the variables most influential are: sexism and nativism – aligning with our hypothesis that ideology influences voter intentions. 

Although the random forest performed similarly to the multinomial regression model in terms of prediction accuracy, we also decided to try a K-NN model to see whether the proximity-based logic of k-nearest neighbors would pick up on the potential clustering of voters with similar ideological preferences. If our hypothesis is true and the do covariates cluster around the same voter intentions, this model would be able to leverage these insights and make better classification predictions. This model was also favorable because it provided class-based insights into sensitivity and specificity. 

# Results

## Random Forest

The random forest model, with 500 trees and considering three variables at each split, achieved an accuracy of 37.5% on the portion of our data reserved for testing the models. This accuracy is at least twice better than chance (random decision between one of six parties being approximately 16%). We then examined the relative importance of the variables included in the random forest using the randomForest package’s variable importance plot. This plot visualizes both the mean decrease in accuracy when a variable is randomized into noise and the mean decrease in Gini impurity index when a variable is considered at split. The variable measuring sexism is rated the highest importance for both these measures; the variable measuring nativism is rated second most important considering the mean decrease in accuracy and third most important when considering Gini impurity decreases. Sexism and nativism being the most important pieces of information when categorizing voter intention reflects the original authors’ study, where they examined the effect of sexism on intent to vote for the far right party Vox.

While the random forest model is not reliably accurate, its information regarding importance of variables is still useful when continuing to analyze the KNN models.

```{r, echo=FALSE, message=FALSE, warning=FALSE}

datread <- read.csv("df_clean.csv")

dat <- datread |> 
  mutate(
    voteintentionspain = factor(voteintentionspain),
    voteintentionspain = recode(voteintentionspain, "1" = "PSOE", "2" = "PP", "3" = "Podemos", "4" = "Ciduadanos", "7" = "ERC", "23" = "Vox"),
    edu3 = factor(edu3),
    female = factor(female),
    femdemonstrate = factor(femdemonstrate)
  )


## 80-20 train-test split, partitioned with caret
set.seed(123)
train_idx <- createDataPartition(dat$voteintentionspain, p = 0.8, list = FALSE)
train_data <- dat[train_idx, ]
test_data <- dat[-train_idx, ]


# Make sure voteintentionspain is a factor
train_data$voteintentionspain <- as.factor(train_data$voteintentionspain)

# Fit the model
rf_model <- randomForest(voteintentionspain ~ dhincome_all + female + 
                           nativism + msexism + femdemonstrate,
                         data = train_data,
                         ntree = 500,           # Number of trees
                         mtry = 3,              # Number of variables tried at each split (default = sqrt(p))
                         importance = TRUE)     # Enables variable importance measures

# Predict on test set
preds <- predict(rf_model, newdata = test_data)

# Create confusion matrix
conf_mat <- table(Predicted = preds, Actual = test_data$voteintentionspain)

# Calculate accuracy
accuracy <- sum(diag(conf_mat)) / sum(conf_mat)
#print(paste("Accuracy:", round(accuracy * 100, 2), "%"))

# "Accuracy: 35.37 %"

```

```{r, echo=FALSE}

# Convert confusion matrix to data frame for ggplot
conf_df <- as.data.frame(conf_mat)
colnames(conf_df) <- c("Predicted", "Actual", "Freq")

# Plot heatmap
ggplot(conf_df, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), size = 4) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  theme_minimal() +
  labs(title = "Random Forest Confusion Matrix",
       x = "Actual Class",
       y = "Predicted Class")

```

```{r, echo=FALSE}

#varImpPlot(rf_model)
varImpPlot(
  rf_model,
  main = "RF Variable Importance Plot",        
  pch = 16,                                  # Optional: change point style                       # Optional: change color
)

```

## K-Nearest Neighbors

We first modeled a “baseline” KNN where k = 3, achieving an accuracy of 33.3% on the test set, before tuning the hyperparameter k. The best k was defined as the k that produces the highest overall accuracy on the test data; after iterating over k = 1 to 100, the best value of k was found to be 63, with an accuracy of 40.2%. Similarly to the random forest, both models perform about twice as well as chance, but not so well that they could be considered accurate when predicting vote intention.

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

## create model over training data, starting with 3-nearest neighbors
## excluding education also
mod = knn3(voteintentionspain ~ dhincome_all + female + nativism + msexism + femdemonstrate, data = train_data, k = 3)
mod

trainpredict = predict(mod, train_data, type="class")
testpredict = predict(mod, test_data, type="class")


trainmatrix = confusionMatrix( 
    factor(trainpredict), 
    factor(train_data$voteintentionspain)
)

testmatrix = confusionMatrix( 
    factor(testpredict), 
    factor(test_data$voteintentionspain)
)

print("Training data matrix:")
print(trainmatrix)
print("Test data matrix:")
print(testmatrix)
```

```{r, echo=FALSE}

# Extract the table from the confusionMatrix object
knn3test_conf_df <- as.data.frame(testmatrix$table)
colnames(knn3test_conf_df) <- c("Predicted", "Actual", "Freq")

# Plot the heatmap
ggplot(knn3test_conf_df, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), size = 4) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  theme_minimal() +
  labs(title = "K-NN Confusion Matrix; k = 3",
       x = "Actual Class",
       y = "Predicted Class")

```

```{r, warning=FALSE, echo=FALSE}

## searching for the best k using accuracy in prediction as the metric -- defining function
bestk = function(k){
    modloop <- knn3(voteintentionspain ~ dhincome_all + female + nativism + msexism + femdemonstrate, data = train_data, k = k)
    acc_test <- round(
        as.numeric(
            confusionMatrix( 
                factor(predict(modloop, test_data, type="class")), 
                factor(test_data$voteintentionspain))$overall[1]
        ), 
        6
    )
    return (acc_test)
}
```

```{r, warning=FALSE, echo=FALSE}

## loop for best k
cv_acc = numeric()
for (k in 1:100) {
    cv_acc[k] = bestk(k)
}
```

```{r, echo=FALSE}

plot(1:100, cv_acc, xlab = 'Value of K', ylab = 'Accuracy', main = "KNN prediction accuracy for k = 1 to 100",
     type = 'l', col = 'blue', lwd = 2)
```

```{r, echo=FALSE, results='hide'}

best_k = 1
best_acc = cv_acc[1]

for (helper in 1:100) {
    if (cv_acc[helper] > best_acc)
        {
            best_k = helper
            best_acc = cv_acc[helper]
        }
}

best_k
best_acc
```

```{r, echo=FALSE, results='hide', warning=FALSE}

## running best k model
mod63 = knn3(voteintentionspain ~ dhincome_all + female + nativism + msexism + femdemonstrate, data = train_data, k = 63)

## training & testing accuracies
trainpredict63 = predict(mod63, train_data, type="class")
testpredict63 = predict(mod63, test_data, type="class")

trainmatrix63 = confusionMatrix( 
    factor(trainpredict63), 
    factor(train_data$voteintentionspain)
)

testmatrix63 = confusionMatrix( 
    factor(testpredict63), 
    factor(test_data$voteintentionspain)
)

print("Training data matrix:")
print(trainmatrix63)
print("Test data matrix:")
print(testmatrix63)
```

```{r, echo=FALSE, warning=FALSE}

## heatmap for best k model
# Extract the table from the confusionMatrix object
test_conf_df63 <- as.data.frame(testmatrix63$table)
colnames(test_conf_df63) <- c("Predicted", "Actual", "Freq")

# Plot the heatmap
ggplot(test_conf_df63, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), size = 4) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  theme_minimal() +
  labs(title = "K-NN Confusion Matrix with highest accuracy; k = 63",
       x = "Actual Class",
       y = "Predicted Class")
```

The confusion matrices give us an opportunity to analyze the behavior of the different k-nn models. When comparing the “baseline” KNN, k = 3, to the random forest model, we see similar patterns in three parties: PSOE, Podemos, and Ciudadanos. These classes are the top three parties that participants intend to vote for, comprising 30.8%, 22.5%, and 19.6% of the data, respectively. The KNN model with the best k, k = 63, also displays bias toward the majority classes. This model never predicts the ERC class and heavily favors PSOE instead, predicting PSOE in 259 out of 604 cases. All models showing bias toward majority classes likely resulted in their similar misclassification patterns.

```{r, echo=FALSE}

plotframe <- data.frame(rfpreds = preds,
                        knn3preds = testpredict,
                        knn63preds = testpredict63,
                          tru = test_data$voteintentionspain,
                          nat = test_data$nativism,
                          sexism = test_data$msexism)
```

We can visualize the models’ predictions with scatterplots, faceted by predicted vote intention. These scatterplots place voters on the axes of sexism and nativism, which are the most important as judged by the random forest’s variable importance plot and variables relevant to identifying placement on political left-to-right scales.

```{r, echo = FALSE}

## scatterplot for random forest classifications
ggplot(plotframe, aes(x = sexism, y = nat, color = tru)) +
  geom_point(data = transform(plotframe, rfpreds = NULL), colour = "grey85") +
  geom_point() +
  facet_wrap(~rfpreds) +
  labs(title = "RF predicted vote intention by sexism and nativism",
       x = "Sexism",
       y = "Nativism",
       color = "True vote intention")
```

```{r, echo=FALSE}

ggplot(plotframe, aes(x = sexism, y = nat, color = tru)) +
  geom_point(data = transform(plotframe, knn3preds = NULL), colour = "grey85") +
  geom_point() +
  facet_wrap(~knn3preds) +
  labs(title = "KNN-predicted vote intention by sexism and nativism",
       subtitle = "k = 3",
       x = "Sexism",
       y = "Nativism",
       color = "True vote intention")
```

```{r, echo=FALSE}

## scatterplot for knn where k = 63, highest accuracy
ggplot(plotframe, aes(x = sexism, y = nat, color = tru)) +
  geom_point(data = transform(plotframe, knn63preds = NULL), colour = "grey85") +
  geom_point() +
  facet_wrap(~knn63preds) +
  labs(title = "KNN-predicted vote intention by sexism and nativism",
       subtitle = "k = 63",
       x = "Sexism",
       y = "Nativism",
       color = "True vote intention")
```

The high variability of colors in each facet, across all models, highlights visually that none of the models are achieving high accuracy. The lack of consistent colors also shows that the models are not consistently miscategorizing one specific party as another. The plot showing the categorization for k = 3 has the most scattered, unclustered patterning across all facets, which means that this model has not picked up on strong patterns for party predictions relative to sexism or nativism. However, this is likely due to the k = 3 and not an essential fault of the k-nearest neighbors algorithm, as the model where k = 63 does show clustering for the different facets. The participants predicted to vote for the far-right party Vox are comprised entirely of the participants with the highest nativism and sexism, clustered in the top right; the participants predicted to vote for the far left party Podemos are clustered in the bottom left, with low scores on the measures of sexism and nativism. The center left party PSOE and the centrist party Ciduadanos also show relatively interpretable patterns; predicted PSOE voters tend toward the center on both measures, and predicted Ciduadanos voters tend toward middling sexism with higher nativism. These patterns in measures of sexism and nativism aligning with political party affilation suggests that the KNN model where k = 63 has learned some sort of pattern that reflects reality despite only achieving roughly 40% accuracy. The presence of similar patterns in the random forest scatterplot, although each facet is less clustered than that of the KNN model where k = 63, reflects a similar outcome.

## Comparison of Random Forest and KNN

When observing the predictive models through the use of the multi-model ROC plot, we can see more clearly that when k = 63, the performance is most similar to that of the random forest model in predicting the different parties. The AUC score, which gives a numerical evaluation of the ability of the models to distinguish between different parties, also shows that the KNN where k = 63 and the random forest perform quite similarly. 

```{r, echo=FALSE, warning=FALSE, message=FALSE, results='hide'}
# chunk to test out the ROC and AUC curve - currently using stack overflow as a resource

# KNN ROC
test_probs <- predict(mod, test_data, type = "prob")
test_labels <- factor(test_data$voteintentionspain, levels = c("PSOE", "PP", "Podemos", "Ciduadanos", "ERC", "Vox"))

roc_knn <- multiclass.roc(test_labels, test_probs, levels=c("PSOE", "PP", "Podemos", "Ciduadanos", "ERC", "Vox"))
#print(roc_knn)

# KNN ROC K = 63
test_probs_63 <- predict(mod63, test_data, type = "prob")
test_labels_63 <- factor(test_data$voteintentionspain, levels = c("PSOE", "PP", "Podemos", "Ciduadanos", "ERC", "Vox"))

roc_knn63 <- multiclass.roc(test_labels_63, test_probs_63, levels=c("PSOE", "PP", "Podemos", "Ciduadanos", "ERC", "Vox"))
#print(roc_knn63)

# RF ROC

test_probs_rf <- predict(rf_model, test_data, type = "prob")
colnames(test_probs_rf) <- c("PSOE", "PP", "Podemos", "Ciduadanos", "ERC", "Vox")
test_labels_rf <- factor(test_data$voteintentionspain, levels = c("PSOE", "PP", "Podemos", "Ciduadanos", "ERC", "Vox"))

roc_RF <- multiclass.roc(test_labels_rf, test_probs_rf, levels = c("PSOE", "PP", "Podemos", "Ciduadanos", "ERC", "Vox"))
#print(roc_RF)

# using: https://stackoverflow.com/questions/72511152/how-to-create-multiple-roc-curves-on-the-same-plot-for-multi-roc-objects-3-cl
```

```{r, echo=FALSE, warning = FALSE, message=FALSE}
# Plotting

Knn_flat <- unlist(roc_knn$rocs, recursive = FALSE)
Knn63_flat <- unlist(roc_knn63$rocs, recursive = FALSE)
RF_flat <- unlist(roc_RF$rocs, recursive = FALSE)

# Start the plot with the first KNN ROC curve
plot(Knn_flat[[1]], col = "red", lwd = 1.7, main = "KNN and RF ROC Curves")

# Add KNN63 curve
plot(Knn63_flat[[1]], add = TRUE, col = "magenta", lwd = 1.7)

# Add RF ROC curve
plot(RF_flat[[1]], add = TRUE, col = "blue", lwd = 1.7)


# Insert a legend
legend("bottomright", legend = c("KNN AUC = 0.6413","KNN 63 AUC = 0.7111",
                                 "RF AUC = 0.6942"), 
                          lty = c(1, 1, 1), 
                          col =c("red", "magenta","blue"), cex=0.6, lwd=1.5, inset = 0.05,
                                  title = "ROC Curves")
                          par(mfrow = c(1, 1))

```

To get further insight on how each model performs, we decided to plot an ROC curve for each party. This confirmed that both KNN when k = 63 and the Random Forest model consistently outperformed the original KNN model. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}

par(mfrow = c(2, 3), oma = c(0, 0, 3, 0)) 
classes = c("PSOE", "PP", "Podemos", "Ciduadanos", "ERC", "Vox")

for (cls in classes) {
  bin_knn <- ifelse(test_labels == cls, 1, 0)
  bin_knn63 <- ifelse(test_labels_63 == cls, 1, 0)
  bin_rf  <- ifelse(test_labels_rf == cls, 1, 0)

  roc_knn_cls <- roc(bin_knn, test_probs[, cls])
  roc_knn63_cls <- roc(bin_knn63, test_probs_63[, cls])
  roc_rf_cls  <- roc(bin_rf, test_probs_rf[, cls])

  plot(roc_knn_cls, col = "red", lwd = 2, main = paste("ROC:", cls))
  plot(roc_knn63_cls, add = TRUE, col = "magenta", lwd = 2)
  plot(roc_rf_cls, add = TRUE, col = "blue", lwd = 2)
  legend("bottomright", 
         legend = c(
           paste("KNN AUC =", round(auc(roc_knn_cls), 2)),
           paste("KNN 63 AUC =", round(auc(roc_knn63_cls), 2)),
           paste("RF AUC =", round(auc(roc_rf_cls), 2))),
         col = c("red", "magenta", "blue"), 
         lwd = 1, cex = 0.35)
}

mtext( "ROC Curves by Model and Party", outer = TRUE, cex = 1, line = 0)
# more on the legend: https://stackoverflow.com/questions/75722676/make-a-legend-for-a-roc-curve-with-colors
```

```{}
```

Despite being the two parties with the lowest numbers of cases, ERC and Vox are the two parties in which all models perform best. The independent variables we have chosen may be more helpful in determining votes for certain parties as opposed to others, especially considering that Vox is a far right party with strong sexist and nativist views. On the other hand, the fact that the KNN k = 63 models performs well on the ERC party’s ROC curve suggests that the party is such a minority that always predicting non-ERC vote intention makes for good accuracy. 

Moreover, despite a large number of cases, the models perform badly on the center-aligned parties. The center left PSOE party holds the most intended votes and the worst performance on its specific ROC plot; the center right PP party holds 12.3% of intended votes and the second worst performance on its ROC plot; and the centrist Ciudadanos party holds 22.5% of intended votes and the third-worst performance on its ROC plot. These patterns do not align with bias for or against majority classes. Instead, the independent variables analyzed here may not be strong predictors for relatively center political parties.

# Discussion

Every model achieves similar accuracy performance on the test data, ranging only from 37.5% to 40.2%; a difference of approximately only 3%. Although all models perform at least twice as well as chance, given that there are six different parties to classify, the overall lack of accuracy suggests that the conceptual space cannot be so easily divided or mapped by the classification algorithms we used. The random forest approach’s inflexible decision boundaries may not be suited to predicting vote intention out of these six independent variables. The k-nearest neighbors approach, which asserts that new data points can be categorized according to those nearest it, performs poorly when k is set very low, and best when k = 63, which is approximately 10% of the test dataset size. Visually observable patterns at k = 63, versus the lack of visual patterns at k = 3, suggests that the k-nearest neighbors model can pick up patterns relative to measures of nativism and sexism when casting a wider net than just the three closest neighbors, which makes sense; vote intention is complex, and cannot be accurately predicted just from the three closest datapoints.

However, the patterns that can be predicted align with parties that have the strongest views. Vox and Podemos, on the far right and far left respectively, show the most obvious clustering relative to measures of nativism and sexism across all models, implying that these variables reflect patterns that the models have learned about which voters are predicted to vote for which party, despite the models’ relative inaccuracy. Similarly interpretable patterns appear for Ciduadanos and PSOE, which are centrist and center left parties. Fascinatingly, this is in spite of the models’ low performance on predicting these parties; recall that these parties were the third-worst and worst performance as measured by AUC, for all models.

These patterns regarding nativism and sexism in the models’ predictions, despite the models’ relatively low accuracy, suggests that other variables still contribute to the models’ categorizations, even if these two variables are highest on measures of importance. 

# References

Anduiza, Eva, and Guillem Rico. 2024. "Sexism and the Far-Right Vote: The Individual Dynamics of Gender Backlash." American Journal of Political Science 68 (2): 478–493.<https://doi.org/10.1111/ajps.12759>.

Hernández Pérez, Enrique, Eva Anduiza Perea, Carol Galais González, Guillem Rico Camps, Jordi Muñoz Mendoza, María José Hierro Hernández, Roberto Pannico, Berta Barbet Porta, and Dani Marinova. 2021. “POLAT Project: Spanish Political Attitudes Panel Dataset (Waves 1–6).” Universitat Autònoma de Barcelona.<https://ddd.uab.cat/record/243399> (accessed September 13, 2021).

## Data

Anduiza, Eva, and Guillem Rico. 2022. Replication Data for: Sexism and the Far-Right Vote: The Individual Dynamics of Gender Backlash. Harvard Dataverse.<https://doi.org/10.7910/DVN/A11CD5>.

## Appendix

### Baseline Multinomial Regression Model

```{r, echo=FALSE}

#Multinomial Regression 


#Model 1 - Basic multinomial model 
mnl.fit <- multinom(voteintentionspain ~ dhincome_all + female + nativism + msexism + femdemonstrate , Hess=T, model=T, data=df, maxit=200) #model

summary(mnl.fit)

## deleted re-processing data so we can make sure all models run on same data -- allison

# Fit model on training data
mod1 <- multinom(voteintentionspain ~ dhincome_all + 
                    nativism + msexism + femdemonstrate,
                    Hess = TRUE, model = TRUE, data = train_data, maxit = 200)

# Step 4: Predict on test data
pred_class <- predict(mnl.fit, newdata = test_data)

# Step 5: Evaluate accuracy
confusion_matrix <- table(Predicted = pred_class, Actual = test_data$voteintentionspain)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)

print(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 3)))


#This model is predicting 1 (PSOE) a lot more than the other categories. Why might this be? 
#Accuracy 40.9 % 
```

```{r, echo=FALSE}

df$voteintentionspain <- as.factor(df$voteintentionspain)


# Define training control with 5-fold CV
train_control <- trainControl(method = "cv", number = 10)

# Train the multinomial model using caret's train()

cv_model <- train(voteintentionspain ~ dhincome_all + 
                    nativism + msexism + femdemonstrate,
  data = df,
  method = "multinom",
  trControl = train_control,
  MaxNWts = 10000,
  trace = FALSE
)

# View results
print(cv_model)

# Confusion Matrix
confusion_matrix <- table(Predicted = pred_class, Actual = test_data$voteintentionspain)

# Calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)

print(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 3)))

#accuracy very slightly improved performance 37.7% 
```
