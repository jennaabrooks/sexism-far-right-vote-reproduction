---
title: "Reproduction of 'Sexism and the far-right vote: The Individual dynamics of gender backlash by Eva Anduiza & Guillem Rico"
author: "Jenna Brooks"
format: pdf
editor: visual
execute:
  echo: false
---

```{r echo = F}
# Load required packages (install using `install.packages()`ibrary(tidyverse)
library(ragg)
library(ggridges)
library(ggrepel)
library(brglm2)
library(stargazer)
library(marginaleffects)
library(survey)
library(dplyr)
library(broom)
library(corrplot)
library(haven)
```

# Reproduction of "Sexism and the far-right vote: The individual dynamics of gender backlash"

Authors: Eva Anduiza & Guillem Rico

This paper examines how sexism has played a role the electoral rise of the far-right party, Vox, in Spain. Anduiza and Rico () argue that having sexist beliefs is one of the most influential attitudinal predictors of voting for the far-right party Vox.

## Original Study

### Data

Using panel data from Spain, collected before, during and after prominent feminist protests in 2018 and 2019, the authors assess individual changes in measures of sexism occurring in various contexts of feminist movement and the surge of far right support.

The data utilized in this study is drawn from the Spanish Political Attitudes dataset (Hernández Pérez et al., 2021), a longitudinal online panel survey conducted annually. The survey uses a quota sampling method to ensure a representative sample of the Spanish adult population aged 18 to 56, with quotas based on gender, age, educational background, geographic region, and municipality size. The unit of analysis is individual voters in Spain.

Observational independence could be questioned in this data set due to the longitudinal design (repeated observations) and the geographic clustering of like-minded voters in specific regions, as well as demographic factors such as age, gender, and education.

This study specifically examines the four survey waves conducted between 2017 and 2020, as these waves include the modern sexism battery, which is central to the analysis. Key to the analysis was the collection of the first wave of data before the first massive feminist movement and the second wave before the rise of the far-right party Vox.

### Dependent Variable: Vote for Vox

The dependent variable in this study is binary – the intention to vote for Vox, coded as 1, with all other responses, including non-responses and nonvoters, coded as 0. This measure is based on respondents' answers to the question, "Which party would you vote for if the general elections were tomorrow?" The authors chose to analyze voting intention rather than past voting behavior to capture respondents' support for Vox at the exact moment of their interview. Given that Vox did not gain significant traction until late 2018, the analysis of voter intention is restricted to the 2019 and 2020 waves of the survey.

The dataset initially comprised 7,850 observations for vote intentions. However, after filtering the data to include only the years 2019 and 2020, the total number of observations was reduced to 3,491. Within this subset, 258 observations (approximately 7.39%) correspond to votes for Vox, the dependent variable of interest, while the remaining 3,233 observations (approximately 92.61%) represent votes for other political parties in Spain.

```{r echo=FALSE}

data <- read.csv("~/Documents/GitHub/sexismfarrightvote/cleaned.csv")

```

# ```{r}
# table(data_2020$vim_vox)
# ```

```{r}
library(ggplot2)
library(dplyr)

# Filter data for years 2019 and 2020
filtered_data <- data %>%
  filter(year %in% c(2019, 2020))

# Plot histogram
ggplot(filtered_data, aes(x = factor(vim_vox))) +
  geom_bar(fill = "blue", color = "black", alpha = 0.7) +
  scale_x_discrete(labels = c("0" = "No", "1" = "Yes")) +
  labs(
    title = "Histogram of Intended Votes for Vox (2019 & 2020)",
    x = "Intended Vote for Vox",
    y = "Count"
  ) +
  theme_minimal() +
  theme(panel.grid = element_blank())

# Count occurrences of vim_vox (0 vs. 1) in 2019 and 2020
table(filtered_data$vim_vox)


```

The histogram above, which depicts intended votes for Vox (coded as 1 for "Yes" and 0 for "No"), continues to show a binary distribution, with a significantly higher frequency of 0s (non-Vox voters) compared to 1s (Vox voters). This refined approach provides a more precise assessment of Vox's appeal during its period of rising popularity.

**Plot and Distribution:**

The dataset comprises a total of 7,850 observations for vote intentions, of which 299 instances (approximately 3.81%) correspond to votes for Vox, the dependent variable of interest, while the remaining 7,551 observations (approximately 96.19%) represent votes for other political parties in Spain. The histogram above, which represents the intended vote for Vox (coded 1 for Yes, 0 for No), shows a binary distribution, with a higher frequency of 0s (non-Vox voters) compared to 1s (Vox voters).

### Data Cleaning and Missing Data

-   Income (missing values imputed from other waves)

-   na.rm = True a lot for NAs

-   The (.=.) part ensures that missing values (.) in the original variables are preserved in the new variables. (under modern sexism scale)

```{r}
# Load packages
library(ggplot2)
library(naniar)
library(dplyr)

# Select relevant variables
vars <- c("vim_vox", "female", "age", "t1edu3", "dhincome_all", 
          "livingpartner", "intpol", "authoritarian", "ideol", 
          "nativism", "orgterr", "pop6amz", "msexism")

# Ensure the variables are numeric (convert categorical variables as necessary)
data_clean <- data %>%
  mutate(across(where(is.factor), as.numeric))  # Convert factors to numeric
all(vars %in% names(data))

# data_miss <- data_clean %>%
#   select(where(~ any(is.na(.))))  # Keep only columns with NAs

# Generate for only variables with missing data
gg_miss_var(data_miss) +
  theme(
    axis.text.y = element_text(size = 10, hjust = 1),  # Increase font size
    axis.ticks.y = element_blank(),  # Remove unnecessary ticks
    panel.grid.major.y = element_blank()  # Reduce grid clutter
  )

```

### Other Attitudinal Factors

Anduiza and Rico include a set of control variables to account for potential confounding factors leading to a vote for the far right. These factors included **General ideological identification**, measured on an 11-point left–right scale; **Authoritarianism**, assessed using a 4-item battery based on childrearing values (Feldman and Stenner 1997); **Nativism**, which evaluates attitudes toward the economic and cultural impacts of migration; **Populist attitudes**, operationalized using the framework developed by Akkerman, Mudde, and Zaslove (2014); and **Territorial preferences**, where higher values indicate stronger support for decentralization. Additionally, the model controlled for sex, age, education (middle school or less, high school/vocational training, college), whether the respondent lives with a partner, household income (a scale with 12 intervals), and a 4-point measure of interest in politics. With the exception of age (in years), all variables were recoded to run from zero to one.

### Table 1 (Replication of Original Paper)

My analysis will be replicating Table 1 "Predictors of Intention to Vote for Vox in 2019 and 2020" (pg.487). The authors hope to achieve a descriptive analysis in this paper, assessing how sexist attitudes, alongside other factors typically associated with voting for the far-right, are associated with support for Vox.

Table 1 displays the the estimates of **two cross-sectional logit models** of intended vote for the 2019 and 2020 waves, respectively:

$$
vox_{it} = sexism_{it} + other\_attitudes_{it} + controls_{it}
$$

where $i$ indexes individuals and $t$ as time (wave); $other\_attitudes_{it}$ encompasses measures of ideology, authoritarianism, nativism, territorial preferences, and populism; and the controls include sex, age, education, income, living with a partner, and interest in politics.

```{r}

# Filter data for 2019 and fit the logistic regression model
t1m1 <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
               livingpartner + intpol + authoritarian + ideol + 
               nativism + orgterr + pop6amz + msexism,
             data = data[data$year == 2019, ],  # Subset the data for 2019
             family = binomial(link = "logit"))

# Filter data for 2020 and fit the logistic regression model
t1m2 <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
               livingpartner + intpol + authoritarian + ideol + 
               nativism + orgterr + pop6amz + msexism,
             data = data[data$year == 2020, ],  # Subset the data for 2020
             family = binomial(link = "logit"))

# Create a table for the two models without AIC, BIC, and R-squared
stargazer(t1m1, t1m2, type = "text", 
          title = "Reproduction of Predictors of Intention to Vote for Vox in 2019 and 2020",
          dep.var.labels = "vim_vox",
          column.labels = c("2019", "2020"),
          # omit.stat = c("aic", "bic", "rsq"),  # Omit AIC, BIC, and R-squared
          stats = c("n"),  # Only display the number of observations
          out = "model_comparison.txt")

```

\![**Author's Table 1 reflects the same results as my table above.**\]

The models indicate that the effects of the attitudinal variables align with the authors' expectations: support for Vox was positively associated with right-wing ideology, sexism, nativism, and populist attitudes (with the latter reaching statistical significance only in 2020), while it is negatively associated with attitudes favoring decentralization. Among these factors, modern sexism has the second-largest impact, surpassed only by ideological orientation. When holding all other variables constant at their observed values, individuals in the 95th percentile of the sexism scale are 8.6 percentage points (in 2019) and 9.9 percentage points (in 2020) more likely to express an intention to vote for Vox compared to those in the 5th percentile. This reiterates the authors' argument that sexism plays a prominent role in an intention to vote for the far-right party, Vox.

## A correlation matrix for the DV and IVs that the original authors included in the model you are replicating

```{r}


# Compute the correlation matrix
cor_matrix <- cor(data_clean[, vars], use = "pairwise.complete.obs", method = "pearson")

# Visualize the correlation matrix using corrplot
corrplot(cor_matrix, 
         method = "color",   # Use color for better visualization
         type = "full",      # Show the full matrix (including lower triangle)
         tl.cex = 0.8,       # Adjust text label size
         tl.col = "black",   # Color of text labels
         addCoef.col = "white",  # Add correlation coefficients in white
         number.cex = 0.7,   # Adjust size of numbers
         col = colorRampPalette(c("blue", "white", "red"))(200))  # Color scale

```


# Additional Models

### Different Link Functions

In my analysis, I chose to focus specifically on the 2020 data from Table 1 to simplify the comparison of the models. I fit two additional models to the original – a probit and a cloglog model on the same dependent variable and covariates.

My primary aim was to investigate whether altering the link function from logit to probit or cloglog resulted in any measurable differences in performance. This exploration was driven by an interest in understanding the comparative behavior of probit, logit, and cloglog models when applied to binary data, particularly in terms of their predictive accuracy and suitability for the dataset.

Specifically, I was interested in the cloglog to anlayze instances of rare events in binary data. Given the low frequency of "1"s in the dependent variable (a vote for Vox), I hypothesized that rare events might be a significant feature of my dataset. By incorporating the cloglog, I aimed to ensure that the analysis could effectively capture and model the infrequent occurrences of the event of interest, providing a more robust evaluation of the data. \#### Probit and ClogLog:

```{r}
# Filter data for 2019 and fit the probit model
t1prob2 <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
               livingpartner + intpol + authoritarian + ideol + 
               nativism + orgterr + pop6amz + msexism,
             data = data[data$year == 2020, ],  # Subset the data for 2020
             family = binomial(link = "probit"))

# Filter data for 2020 and fit the logistic regression model
t1cloglog2 <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
               livingpartner + intpol + authoritarian + ideol + 
               nativism + orgterr + pop6amz + msexism,
             data = data[data$year == 2020, ],  # Subset the data for 2020
             family = binomial(link = "cloglog"))

stargazer(t1m2, t1prob2, t1cloglog2, type = "text", 
          title = "Reproduction of Predictors of Intention to Vote for Vox in 2020",
          dep.var.labels = "vim_vox",
          column.labels = c("2020 Logit", "2020 Probit", "2020 Cloglog"),
          out = "model_comparison.txt")
```

##### In Sample Comparison of Models

As shown in the table above, the original logit model outperforms both the probit and cloglog models. The logit model has the lowest AIC value, which suggests better in-sample performance. The cloglog model ranks second in terms of AIC, while the probit model ranks third for in- sample performance, however the relative difference in performance is negligible. Furthermore, the logit model achieves the highest log-likelihood value, further confirming its better performance. These results indicate that the original logit model is the most effective among the three for this dataset.

When testing out these models in out of sample performance in cross validation, I frequently received NA values for the MSEs. I believe this is due to the low number of 1's in my data set compared to 0's ( with 1846 0's and 162 1's in the year 2020 ) leading to perfect separation in my sample. To remediate this issue, I decided to combine the years 2019 and 2020 in my models to allow them to train on more data.

#### Simpler Model

```{r}
# Load necessary libraries
library(caret)

# Assuming your dataset is named 'data' and contains the outcome variable 'vim_vox'

# Filter data for 2020
data_2020 <- data[data$year == 2020, ]

# Define a function to compute MSE
compute_mse <- function(model, test_data) {
  preds <- predict(model, newdata = test_data, type = "response")  # Predicted probabilities
  mse <- mean((test_data$vim_vox - preds)^2)  # Compute MSE
  return(mse)
}

# Set number of folds
set.seed(123)  # For reproducibility
k <- 10  # Number of folds

# Create stratified folds based on the outcome variable 'vim_vox'
folds <- createFolds(data_2020$vim_vox, k = k, list = TRUE, returnTrain = FALSE)

# Initialize vectors to store MSEs
mse_t1simp <- numeric(k)
mse_t1m2 <- numeric(k)

# Perform cross-validation
for (i in 1:k) {
  # Split data into training and test sets
  train_data <- data_2020[-folds[[i]], ]
  test_data <- data_2020[folds[[i]], ]
  
  # Fit t1simp model on training data
  model_t1simp <- glm(vim_vox ~ authoritarian + ideol + 
                        nativism + orgterr + pop6amz + msexism,
                      data = train_data, family = binomial(link = "logit"))
  
  # Fit t1m2 model on training data
  model_t1m2 <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
                      livingpartner + intpol + authoritarian + ideol + 
                      nativism + orgterr + pop6amz + msexism,
                    data = train_data, family = binomial(link = "logit"))
  
  # Compute MSE on test data
  mse_t1simp[i] <- compute_mse(model_t1simp, test_data)
  mse_t1m2[i] <- compute_mse(model_t1m2, test_data)
}

# Calculate mean MSE and standard errors
mean_mse_t1simp <- mean(mse_t1simp)
mean_mse_t1m2 <- mean(mse_t1m2)

se_mse_t1simp <- sd(mse_t1simp) / sqrt(k)
se_mse_t1m2 <- sd(mse_t1m2) / sqrt(k)

# Compare the two models
cat("Mean MSE for t1simp:", mean_mse_t1simp, "(SE:", se_mse_t1simp, ")\n")
cat("Mean MSE for t1m2:", mean_mse_t1m2, "(SE:", se_mse_t1m2, ")\n")

```

# Cross Validation on simple model

```{r}
# # Load necessary libraries
# library(caret)
# 
# 
# # Define a function to compute MSE
# compute_mse <- function(model, test_data) {
#   preds <- predict(model, newdata = test_data, type = "response")  # Predicted probabilities
#   mse <- mean((test_data$outcome - preds)^2)  # Compute MSE
#   return(mse)
# }
# 
# # Set number of folds
# set.seed(123)  # For reproducibility
# k <- 10  # Number of folds
# 
# # Create stratified folds based on the outcome variable (e.g., 'outcome')
# folds <- createFolds(data$outcome, k = k, list = TRUE, returnTrain = FALSE)
# 
# # Initialize vectors to store MSEs
# mse_t1simp <- numeric(k)
# mse_t1m2 <- numeric(k)
# 
# # Perform cross-validation
# for (i in 1:k) {
#   # Split data into training and test sets
#   train_data <- data[-folds[[i]], ]
#   test_data <- data[folds[[i]], ]
#   
#   # Refit t1simp model on training data (if necessary)
#   # Assuming t1simp is a formula-based model (e.g., glm)
#   t1simp_formula <- as.formula("outcome ~ predictor1 + predictor2 + ...")  # Replace with t1simp's formula
#   model_t1simp <- glm(t1simp_formula, data = train_data, family = binomial(link = "logit"))
#   
#   # Refit t1m2 model on training data (if necessary)
#   # Assuming t1m2 is a formula-based model (e.g., glm)
#   t1m2_formula <- as.formula("outcome ~ predictor1 + predictor2 + ...")  # Replace with t1m2's formula
#   model_t1m2 <- glm(t1m2_formula, data = train_data, family = binomial(link = "logit"))
#   
#   # Compute MSE on test data
```

# I tried CV with both 2019 and 2020 data

```{r}
library(caret)  # For creating cross-validation folds
library(dplyr)

# Filter data for 2020 and 2019
data_combo <- data %>%
  filter(year %in% c(2019, 2020))

# Define a function to compute MSE
compute_mse <- function(model, test_data) {
  preds <- predict(model, newdata = test_data, type = "response")  # Predicted probabilities
  mse <- mean((test_data$vim_vox - preds)^2)  # Compute MSE
  return(mse)
}

# Set number of folds
set.seed(123)  # For reproducibility
k <- 10

# Create stratified folds based on the dependent variable (vim_vox)
folds <- createFolds(data_combo$vim_vox, k = k, list = TRUE, returnTrain = FALSE)

# Initialize vectors to store MSEs
mse_logit <- numeric(k)
mse_probit <- numeric(k)
mse_cloglog <- numeric(k)



# Perform cross-validation
for (i in 1:k) {
  # Split data into training and test sets
  train_data <- data_combo[-folds[[i]], ]
  test_data <- data_combo[folds[[i]], ]
  
  # Fit models on training data
  model_logit <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
                        livingpartner + intpol + authoritarian + ideol + 
                        nativism + orgterr + pop6amz + msexism,
                      data = train_data, family = binomial(link = "logit"))
  
  model_probit <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
                        livingpartner + intpol + authoritarian + ideol + 
                        nativism + orgterr + pop6amz + msexism,
                      data = train_data, family = binomial(link = "probit"))
  
  model_cloglog <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
                          livingpartner + intpol + authoritarian + ideol + 
                          nativism + orgterr + pop6amz + msexism,
                        data = train_data, family = binomial(link = "cloglog"))
  
    # Compute MSE on test data
  mse_logit[i] <- compute_mse(model_logit, test_data)
  mse_probit[i] <- compute_mse(model_probit, test_data)
  mse_cloglog[i] <- compute_mse(model_cloglog, test_data)
}

# Calculate mean MSE and standard errors
mean_mse <- c(mean(mse_logit), mean(mse_probit), mean(mse_cloglog))
se_mse <- c(sd(mse_logit) / sqrt(k), sd(mse_probit) / sqrt(k), sd(mse_cloglog) / sqrt(k))

# Find the model with the smallest MSE
best_index <- which.min(mean_mse)

# Format results: Standard error in parentheses for the best model
mse_results <- sprintf("%.5f", mean_mse)
mse_results[best_index] <- sprintf("%.5f (%.5f)", mean_mse[best_index], se_mse[best_index])

# Print results
model_names <- c("Logit", "Probit", "Cloglog")
results_df <- data.frame(Model = model_names, MSE = mse_results)
print(results_df)

```

##### Out of Sample Performance: 10-Fold Cross Validation

There is evidence of perfect separation in my dataset.

# I tried CV with just 2020 data and stratifying the folds.

```{r}
library(caret)  # For creating cross-validation folds

# Filter data for 2020
data_2020 <- data[data$year == 2020, ]  

# Define a function to compute MSE
compute_mse <- function(model, test_data) {
  preds <- predict(model, newdata = test_data, type = "response")  # Predicted probabilities
  mse <- mean((test_data$vim_vox - preds)^2)  # Compute MSE
  return(mse)
}

# Set number of folds
set.seed(123)  # For reproducibility
k <- 10

# Create stratified folds based on the dependent variable (vim_vox)
folds <- createFolds(data_2020$vim_vox, k = k, list = TRUE, returnTrain = FALSE)

# Initialize vectors to store MSEs
mse_logit <- numeric(k)
mse_probit <- numeric(k)
mse_cloglog <- numeric(k)



# Perform cross-validation
for (i in 1:k) {
  # Split data into training and test sets
  train_data <- data_2020[-folds[[i]], ]
  test_data <- data_2020[folds[[i]], ]
  
  # Fit models on training data
  model_logit <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
                        livingpartner + intpol + authoritarian + ideol + 
                        nativism + orgterr + pop6amz + msexism,
                      data = train_data, family = binomial(link = "logit"))
  
  model_probit <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
                        livingpartner + intpol + authoritarian + ideol + 
                        nativism + orgterr + pop6amz + msexism,
                      data = train_data, family = binomial(link = "probit"))
  
  model_cloglog <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
                          livingpartner + intpol + authoritarian + ideol + 
                          nativism + orgterr + pop6amz + msexism,
                        data = train_data, family = binomial(link = "cloglog"))
  
    # Compute MSE on test data
  mse_logit[i] <- compute_mse(model_logit, test_data)
  mse_probit[i] <- compute_mse(model_probit, test_data)
  mse_cloglog[i] <- compute_mse(model_cloglog, test_data)
}

# Calculate mean MSE and standard errors
mean_mse <- c(mean(mse_logit), mean(mse_probit), mean(mse_cloglog))
se_mse <- c(sd(mse_logit) / sqrt(k), sd(mse_probit) / sqrt(k), sd(mse_cloglog) / sqrt(k))

# Find the model with the smallest MSE
best_index <- which.min(mean_mse)

# Format results: Standard error in parentheses for the best model
mse_results <- sprintf("%.5f", mean_mse)
mse_results[best_index] <- sprintf("%.5f (%.5f)", mean_mse[best_index], se_mse[best_index])

# Print results
model_names <- c("Logit", "Probit", "Cloglog")
results_df <- data.frame(Model = model_names, MSE = mse_results)
print(results_df)


```

## Cross Validation

## Interpretive Exercise (Scenarios)

In the original study, the authors highlight the growing influence of sexist attitudes on election outcomes for far-right parties. While anti-feminism is not the central focus of Vox, the party has employed anti-feminist rhetoric, portraying feminists as “violent,” “radical,” and “communist,” while also denying the existence of discrimination against women(). Based on this, the authors hypothesize that increasing levels of sexism among voters may contribute to the rise of Vox in Spain.

To explore this relationship further, I examined how sexist attitudes in `msexism`, measured in the range from 0 to 1 (), influence support for Vox by constructing voter scenarios. Using the best-performing model from the original study— the logistic regression model used in the original paper—I created two voter profiles: one scoring 0.25 (lower sexism) and another scoring 0.75 (moderate to high sexism) on the modern sexism scale. This allowed me to analyze how the likelihood of voting for Vox differs between those who strongly reject versus strongly endorse sexist beliefs. The scale captures perceptions of gender equality, including beliefs about ongoing discrimination, differences in opportunities, and the legitimacy of feminist concerns, as well as attitudes toward media representations, government efforts, and policies addressing gender inequality.


##Scenarios

Scenarios - 0.25 / 0.75 I chose these values because 0 and 1 were likely to alwyas vote one way or the other, I wanted to see more moderate sexist voting behavior. 

```{r}
# Filter data for 2020 and fit the logistic regression model
t1m2 <- glm(vim_vox ~ female + age + factor(edu3) + dhincome_all + 
               livingpartner + intpol + authoritarian + ideol + 
               nativism + orgterr + pop6amz + msexism,
             data = data[data$year == 2020, ],  # Subset the data for 2020
             family = binomial(link = "logit"))
# Load necessary package

library(MASS)

# Inverse logit function
inv.logit <- function(x) {
  1 / (1 + exp(-x))
}

# Compute the median values for all covariates
median_values <- data[data$year == 2020, ] %>%
  summarise(
    female = median(female, na.rm = TRUE),
    age = median(age, na.rm = TRUE),
    edu3 = as.numeric(names(which.max(table(edu3)))),
    dhincome_all = median(dhincome_all, na.rm = TRUE),
    livingpartner = median(livingpartner, na.rm = TRUE),
    intpol = median(intpol, na.rm = TRUE),
    authoritarian = median(authoritarian, na.rm = TRUE),
    ideol = median(ideol, na.rm = TRUE),
    nativism = median(nativism, na.rm = TRUE),
    orgterr = median(orgterr, na.rm = TRUE),
    pop6amz = median(pop6amz, na.rm = TRUE)
  )

# Define the range for msexism (0.25 and 0.75)
msexism_values <- c(0.25, 0.75)

# Create the scenario matrices
# Scenario 1: msexism = 0.25
X.lo <- c(1,                                       # intercept
          median_values$female,                    # median female
          median_values$age,                       # median age
          median_values$edu3,                      # mode of edu3 (numeric)
          median_values$dhincome_all,              # median income
          median_values$livingpartner,             # median livingpartner
          median_values$intpol,                    # median intpol
          median_values$authoritarian,             # median authoritarian
          median_values$ideol,                     # median ideol
          median_values$nativism,                  # median nativism
          median_values$orgterr,                   # median orgterr
          median_values$pop6amz,                   # median pop6amz
          0.25)                                    # msexism = 0.25

X.lo <- matrix(X.lo, nrow = 13, ncol = 1)  # Ensure it's a 13x1 column vector

# Scenario 2: msexism = 0.75
X.hi <- c(1,                                       # intercept
          median_values$female,                    # median female
          median_values$age,                       # median age
          median_values$edu3,                      # mode of edu3 (numeric)
          median_values$dhincome_all,              # median income
          median_values$livingpartner,             # median livingpartner
          median_values$intpol,                    # median intpol
          median_values$authoritarian,             # median authoritarian
          median_values$ideol,                     # median ideol
          median_values$nativism,                  # median nativism
          median_values$orgterr,                   # median orgterr
          median_values$pop6amz,                   # median pop6amz
          0.75)                                    # msexism = 0.75

X.hi <- matrix(X.hi, nrow = 13, ncol = 1)  # Ensure it's a 13x1 column vector

# 1000 draws of coefficient vectors from the posterior distribution
B.tilde <- mvrnorm(1000, coef(t1m2), vcov(t1m2))

# Replicate X.lo across 1000 rows to form X.lo_rep (1000 x 13)
X.lo_rep <- matrix(rep(X.lo, 1000), nrow = 1000, byrow = TRUE)

# Check the dimensions to confirm alignment
print(dim(B.tilde))  # Should be 1000 x 14
print(dim(X.lo_rep))  # Should be 1000 x 13

# Compute predicted probabilities for msexism = 0.25 (X.lo)
# Extract the coefficients corresponding to the covariates (not including the intercept)
B.tilde_subset <- B.tilde[, 1:13]  # Extract the first 13 columns

# Compute the predicted probabilities for msexism = 0.25
s.lo <- inv.logit(B.tilde_subset %*% t(X.lo_rep))  # Matrix of predicted probabilities (transpose)

# Check the dimensions of the result
print(dim(s.lo))  # Should be 1000 x 1000

# Compute predicted probabilities for msexism = 0.75 (X.hi)
X.hi_rep <- matrix(rep(X.hi, 1000), nrow = 1000, byrow = TRUE)
s.hi <- inv.logit(B.tilde_subset %*% t(X.hi_rep))  # Matrix of predicted probabilities for msexism = 0.75

# Compute 95% CI and median for both scenarios
s.lo_quantiles <- apply(s.lo, 2, quantile, c(0.025, 0.5, 0.975))  # Confidence intervals for scenario 1
s.hi_quantiles <- apply(s.hi, 2, quantile, c(0.025, 0.5, 0.975))  # Confidence intervals for scenario 2

# Plotting the results
plot(1:1000, s.lo_quantiles[2, ], ylim = c(0, 1), xlab = "Coefficient Draws",
     ylab = "Predicted Probability", main = "Predicted Probabilities for msexism Scenarios", bty = "n", col = "white")

# Confidence region for msexism = 0.25
polygon(x = c(1:1000, rev(1:1000)), y = c(s.lo_quantiles[1, ], rev(s.lo_quantiles[3, ])),
        col = grey(0.8), border = NA)

# Confidence region for msexism = 0.75
polygon(x = c(1:1000, rev(1:1000)), y = c(s.hi_quantiles[1, ], rev(s.hi_quantiles[3, ])),
        col = grey(0.8), border = NA)

# Lines for the medians
lines(1:1000, s.hi_quantiles[2, ], lty = 3, lwd = 2)  # Median for msexism = 0.75
lines(1:1000, s.lo_quantiles[2, ], lwd = 2)           # Median for msexism = 0.25

# Add legend
legend("topright", legend = c("msexism = 0.25", "msexism = 0.75"), lty = c(1, 3), lwd = 3)


```



-   

# Limitations

The authors mention "We, thus, cannot rule out that Vox voters’ opinions on women’s discrimination are actually a consequence, rather than a cause, of their partisan preferences." (pg. 486)

Evaluate both models and come to a conclusion based on the

Use cross validation to get out of sample error for OG and your new model –\> based on what I did, my new model doesn't really add anything to the outcome

not trying to overturn the author's original findings. or find a better model

# Citations:

Swim et al (1995) Stargazer Library

# AI Appendix Statement (update this):

-   I used ChatGPT LLM/AI tool in this assignment.

-   I used it to help write the code for the plots.  

-   I found it helpful in getting the results I was looking for and understanding the concept of a correlation matrix. Also helped with converting DTA to CSV

-   Link: <https://chatgpt.com/share/67af9007-561c-800f-9f0f-367b9f306c7e>

Link2: <https://chatgpt.com/share/67af908c-6de0-800f-aca5-1a1cdb82be69>

Link3: <https://chatgpt.com/c/67c76a1c-e874-800d-84f0-e5ddc106c044>

Link4:\
